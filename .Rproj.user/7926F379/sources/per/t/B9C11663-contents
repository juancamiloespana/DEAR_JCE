#visualizaci?n de nuestra base de datos para ver si est? bien le?da o no 
head(hour)
tail(hour)
#################################################################################################
#identificando variables 
str(hour)       #Tenemos muchas variables Dummy y las vamos a trabajar como cualitativas, nos                    dice cual es la estructura, si son valores num?ricos, factores o enteros, las                    variables dummy son las que toman dos, tres o m?s valores pero son finitos.

summary(hour)   #Para ver que los datos est?n bien, no tengan anomal?as e identificar posibles                   valores at?picos 
################################################################################################

#Vamos a redefinir las variables para que no se tomen como cuantitativas sino como cualitativas 
hour$season <- as.factor(hour$season)
hour$yr <- as.factor(hour$yr)
hour$holiday <- as.factor(hour$holiday)
hour$workingday <- as.factor(hour$workingday)
hour$weathersit <- as.factor(hour$weathersit)
hour$mnth <- as.factor(hour$mnth)
hour$weekday <- as.factor(hour$weekday)
hour$hr <- as.factor(hour$hr)
hour$temp <- as.numeric(hour$temp)
hour$atemp <- as.numeric(hour$atemp)
hour$hum <- as.numeric(hour$hum)
hour$windspeed <- as.numeric(hour$windspeed)
hour$casual <- as.numeric(hour$casual)
hour$registered <- as.numeric(hour$registered)
hour$cnt <- as.numeric(hour$cnt)


str(hour)       
summary(hour)
################################################################################################
#identificar datos faltantes, datos extra?os
hourcuali <- hour[c(3,4,5,6,7,8,9,10)] 
hourcuanti <- hour[c(11,12,13,14,15,16,17)] #no trabajaremos con date ni instant porque                                                   son variables que no aportan a la predicci?n del modelo 
################################################################################################

#Matriz de gr?ficos de dispersi?n 

pairs(cnt ~ ., data=hourcuanti, main="Gr?fico Matriz de dispersion")     
                                 #Para esta matriz debemos analizar las relaciones de
                                 #nuestra variable respuesta con las variables regresoras
################################################################################################
#Resumen de correlaciones 
cor(hourcuanti)
# Gr?fico de matriz de correlaci?nes 

library(corrplot)                 #aqui podemos observar de una manera m?s interactiva las 
corrplot(cor(hourcuanti))         #relaciones de nuestra variable respuesta con las variables 
                                  #regresoras 

#######################################################################################



#Modelos

modelo00 <- lm(cnt ~., data= hour)
summary(modelo00)

#Escogimos solamente la base de datos de las variables cuantitativas ya que las variables cualitativas no eran importantes en nuestro modelo de regresi?n y no nos dejaban hacer un buen an?lisis del modelo, adem?s algunos level de las variables no eran significativos y eso hac?a que descartemos toda la variable

model <- lm(cnt ~ ., data= hourcuanti) #este primer modelo es significativo y la mayor?a                                        de las variables regresoras son significativas,                                         el R ajustado nos di? de 1 sin embargo es extra?o                                        ya que no todas las variables regresoras son                                            signinficativas, haremos otro modelo mejorado                                      eliminando las variables que no le aportan al modelo.
summary(model)

#multicolinealidad del modelo 
library(car)
vif(model)            #podemos observar que hay una relaci?n entre las variables                              regresoras de temp y atemp, esto sucede porque una es                                   transformaci?n de la otra por lo tanto s?lo vamos a eliminar una                        del modelo porque como est?n relacionada puede que el modelo no                         sea el mejor si quitamos las dos.

#variables multicolineales
cor(hour$temp, hour$atemp)  #Hay una correlaci?n alta entre estas dos variables 
plot(hour$temp, hour$atemp)   # Tambi?n podemos observar la correlaci?n con esta gr?fica


model1 <- lm(cnt ~. -temp, data = hourcuanti)  #En este modelo todas nuestras variables                                               se volvieron significativas, entonces nos                                               quedamos con este. 
summary(model1)
vif(model1)

#Ahora vamos a probar quitando la variable atemp

model0 <- lm(cnt ~. -atemp, data= hourcuanti)
summary(model0)
vif(model0)

model2 <- lm(cnt ~. -atemp -windspeed, data= hourcuanti)
summary(model2)
vif(model2)

mode <- lm(cnt ~. - atemp - windspeed - hum, data= hourcuanti) 
summary(mode)
vif(mode)

#vamos a considerar el modelo mode ya que adem?s de que las variables son significativas,nos disminuy? las variables y tiene una colinealidad normal, pensamos tambi?n que es m?s importante la variable temp ya que atemp se deriva de esta.  


##############################################################################

#Puntos outliers 

boxplot(hourcuanti,xlab = "Variables regresoras",ylab = "Frecuencia",
        col = c("orange3","yellow3", "grey", "green3", "red"))


require(car)             #Tenemos en cuenta los puntos en las l?neas 1,3 y 4de la base de                            datos ya que sus valores de unajusted p-value y bonferroni p son                             peque?os
outlierTest(mode)


require(olsrr)          #En la gr?fica podemos comprobar que las l?neas 1,2,3 y 4 son puntos                       outliers
id <- ols_plot_resid_lev(mode)
influence.measures(mode)

c <- hour[3,]
d <- hour[4,]

#Eliminaci?n de puntos outliers

hour2 <- hourcuanti[-c(1,2,3,4),]                        
hour2

modelo4 <- lm(cnt ~. -atemp -windspeed - hum, data=hour2)
summary(modelo4)
   

####################################################################################
#An?lisis de residuales 
residualest <- rstandard(modelo4)  

#Normalidad
require(nortest)
shapiro.test(residualest)    #No podemos hacer esta prueba porque hay muchos datos 
ad.test(residualest)        #como el valor p es muy peque?o, se rechaza la hipotesis nula
require(tseries)            #o sea que los datos no siguen una distribuci?n normal 
jarque.bera.test(residualest) 


library(car)
qqPlot(residualest)                      
hist(residualest)



#########################################################################################
#Homocedasticidad 

require(lmtest)
bptest(modelo4)  

valoresob <- fitted.values(modelo4)
plot(valoresob, residualest, ylim=c(-4,4))

plot(hour2$casual, residualest)
plot(hour2$registered, residualest)
plot(hour2$temp, residualest)


###########################################################################################
#Independencia 
require(lmtest)
dwtest(modelo4, alternative="two.sided")                                            
bgtest(modelo4)

plot(residualest)    #como el valor p es peque?o, concluimos que no hay independencia pero como no hay seguridad de la informaci?n, no se va a considerar este supuesto
############################################################################################
#Transformaci?n

hist(hour2$cnt)
qqPlot(hour2$cnt)

trans <- (hour$cnt)^2
############################################################################################
#M?todo backward

backward <- step(modelo4, direction = "backward")
summary(backward)
backward1 <- aov(backward)
summary(backward1)

#Con esta tecnica nos dej? solamente dos variables regresoras y con esto el AIC mejor?, a pesar de haber eliminado variables, el r cuadrado ajustado qued? igual.


#M?todo Forward

forward <- step(modelo4, direction = "forward")
summary(forward)
forwad1 <- aov(forward)
summary(forwad1)


#M?todo Both 

both <- step(modelo4, direction = "both")
summary(both)
both1 <- aov(both)
summary(both1)
 



