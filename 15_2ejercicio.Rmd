---
title: "Ejercicio completo regresión lineal múltiple"
output:
  slidy_presentation: default
  ioslides_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Instalación y carga de paquetes

Los paquetes en R deben ser instalados una vez en el computador, o en el entorno web que se utilice. Se utiliza la función:  

- **install.packages("nombre_paquete")**

Luego de que estén instalados se deben cargar cada vez que se inicie un entorno de R en elque se vayan a usar.

- **library(nombre_paquete)**



## Instalación de paquetes necesarios para el ejercicio

```{r echo=T, message=FALSE, warning=FALSE, eval=F}

#### para gráficos y funciones útiles
install.packages("plotly")
install.packages("dplyr")
install.packages("COUNT")
install.packages("corrplot")
install.packages("skimr")

##### Imputación ######
install.packages("randomForest")

##### Validación supuestos ######
install.packages("car")
install.packages("tseries")
install.packages("nortest")
install.packages("goftest")
install.packages("lmtest")


##### para validar multicolonealidad
install.packages("regclass") # para calcular VIF

##### Para calcular MAPE, RMSE MAE
install.packages("Metrics")

```

## Carga de paquetes


```{r echo=T, message=FALSE, warning=FALSE, eval=T}

library(corrplot) #Gráfico de correlaciones
library(plotly) #para gráficos bonitos
library(Metrics) # para calcular mape
library(regclass) # para VIF
library(car)  # validacion supuestos
library(MASS) # para stepAIC
library(tseries) # validacion supuestos
library(nortest) # validacion supuestos
library(goftest) # validacion supuestos
library(lmtest) # validacion supuestos
library(randomForest) # para imputación de datos faltantes
library(dplyr) # para case_when para reagrupar variables
library(skimr) # Para descripción de datos


```


## Cargar base de datos

1. Primero se debe cargar en el proyecto desde web para Rcloud o en la carpeta si es R local.

2. Después de tenerlo dentro del proyecto se ejecuta código de lectura de csv.

    - Verificar la separación decimal del archivo y las columnas porque puede ser diferente en cada archivo.
    
```{r echo=T, message=FALSE, warning=FALSE, eval=T}


#Leer Base de Datos-ejemplo 


data_original<-read.csv("base_supermercado.csv",dec=",",sep=";", na.strings = "")



```


## Exploración inicial y transformaciones

Se debe tener un conocimiento de la información a trabajar, si no se tiene reunirse con dueños de la información para explicación o leer documentación.

```{r echo=T, message=FALSE, warning=FALSE, eval=T}


# Verificar que haya cargado bien y formatos de campos
str(data_original)

# Exploración inicial, verificar atípicos, números de categorías

skim(data_original)

```

## Cambiar formato de variables

Convertir los variables que se consideren necesarias a factores
Las variables que están en chr, no es necesario convertirlas a factor, pero facilita su análisis con ciertas funciones

```{r echo=T, message=FALSE, warning=FALSE, eval=T}
data_original$cat_principal= as.factor(data_original$cat_principal)
data_original$genero=as.factor(data_original$genero)
data_original$reportado_data_credito= as.factor(data_original$reportado_data_credito)
data_original$medio_apgo= as.factor(data_original$medio_apgo)
data_original$dia_sem_mas_frecuente= as.factor(data_original$dia_sem_mas_frecuente)
data_original$producto_frecuente = as.factor(data_original$producto_frecuente)
data_original$fecha_ultima_compra<-as.factor(data_original$fecha_ultima_compra) 



str(data_original)
skim(data_original)
```

## Identificar y Tratar datos faltantes ####

```{r echo=T, message=FALSE, warning=FALSE, eval=T}



####Faltantes-imputación
table(is.na(data_original))

data_original<-na.roughfix(data_original)
table(is.na(data))

```





## Revisar las categorías de las variables explicativas

Una variable con muchas categorías es difícil de analizar, puede hacer el modelo lento y  generar sobre ajustes. Aunque no hay un número exacto para saber qué son muchas, podría utilizarse más de 20 o 30 como referencia.
Según el estudio este valor se puede aumentar o disminuir
Además se debe revisar que ninguna categoría tenga pocas observaciones.

Con la función table, aplicada a cada columna, se hace un conteo de cuántas observaciones hay por categoría y se ordena (en caso de que haya muchas categorías) para identificar las categorías con mayor número de observaciones.


```{r echo=T, message=FALSE, warning=FALSE, eval=T}
obs_gen<-table(data_original$genero)
obs_gen[order(obs_gen,decreasing=T)]

obs_rep<-table(data_original$reportado_data_credito)
obs_rep[order(obs_rep,decreasing=T)]

obs_cat<-table(data_original$cat_principal)
obs_cat[order(obs_cat,decreasing=T)]

obs_med<-table(data_original$medio_apgo)
obs_med[order(obs_med,decreasing=T)]

obs_prod<-table(data_original$producto_frecuente)
obs_prod[order(obs_prod,decreasing=T)]



data_original$producto_frecuente =
  case_when (
    data_original$producto_frecuente == "Pollo" ~"Pollo",
    data_original$producto_frecuente == "Carne" ~"Carne",
    data_original$producto_frecuente == "Cerveza tibetana Barley" ~"Cerveza",
    TRUE ~ "Otros"
    
  )

data_original$producto_frecuente = as.factor(data_original$producto_frecuente)




str(data_original)
```

## Tratamiento de fechas

Las fechas son un tipo de dato especial, ni categórica ni numérica, pero deberían convertirse a este tipo.

Las fechas se pueden restar para calcular días, se puede extraer el mes, el día de la semana, día del mes o el año.

```{r echo=T, message=FALSE, warning=FALSE, eval=T}

data_original$fecha_ultima_compra2<-as.Date(data_original$fecha_ultima_compra,"%d/%m/%Y") ##se convierte la columna a formato fecha


data_original$fu_mes=months.Date(data_original$fecha_ultima_compra2, abbreviate = T) ### para extraer el mes
data_original$fu_ds=weekdays(data_original$fecha_ultima_compra2, abbreviate = T) ###para extraer el día de la semana
data_original$fu_tri=quarters(data_original$fecha_ultima_compra2, abbreviate = T) ### Para extraer el trimestre

data_original$fu_dm=format(data_original$fecha_ultima_compra2, format="%d") ###Para extraer el día del mes
data_original$fu_a=format(data_original$fecha_ultima_compra2, format="%Y") ## para extraer el año



data_original$fu_mes=as.factor(data_original$fu_mes)
data_original$fu_ds=as.factor(data_original$fu_ds)
data_original$fu_tri=as.factor(data_original$fu_tri)
data_original$fu_dm=as.factor(data_original$fu_dm)
data_original$fu_a=as.factor(data_original$fu_a)

str(data_original)
```



## Análisis exploratorio

Eliminar de la base las variables repetidas o que no se analizan

La variable respuesta es la más importante y la que más se debería explorar, en cuanto a su comportamiento y su relación con las explicativas.

El análisis exploratorio depende de la creatividad del investigador muestra su capacidad para encontrar insights (hallazgos o conclusiones).

El análisis exploratorio es fundamental y suele ser el primer entregable de un análisis de datos, muchas veces el único.


```{r echo=T, message=FALSE, warning=FALSE, eval=T}
data<-data_original[,-c(1,20,22) ]

hist(data$y, main= "Histograma de compras mensuales por cliente",
     ylab="Frecuencia", xlab="Promedio compras mensuales por cliente") ##
boxplot(data$y, horizontal = T)

qqPlot(data$y)

jarque.bera.test(data$y)

plot_ly(data=data,x=~y , type="histogram" )%>%
  layout(title="Histograma de compras mensuales por cliente",
         yaxis=list(title="Frecuencia"),xaxis=list(title="Histograma de compras mensuales por cliente"))
```

## Eliminación de datos inusuales

La eliminación de atípicos de la variable respuesta es indispensable para mejorar el desempeño del modelo.

La eliminación de atípicos en las explicativas es recomendable pero no suele tener un impacto tan fuerte

```{r echo=F, message=FALSE, warning=FALSE, eval=T}

# Eliminar atípicos de variable respuesta
lim_sup<- quantile(data$y,0.75) +(IQR(data$y)*1.5 ) 
lim_inf<- quantile(data$y,0.25) - (IQR(data$y)*1.5 ) 

data=subset(data, data$y<=lim_sup & data$y>lim_inf)


# Eliminar atipicos según su influencia en el modelo

mod<-lm(y~.,data=data)
datos_influyentes<- influence.measures(mod)

influyentes<-summary(datos_influyentes)
filas_filtrar<-as.numeric(row.names(influyentes))

data<-data[-filas_filtrar, ]

dim(data)

```